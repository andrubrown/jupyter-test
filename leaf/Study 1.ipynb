{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study 1 for leaf recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model, preprocessing, svm\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "import math\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from scipy.stats import boxcox\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### TODO\n",
    "1. ~~basic info~~\n",
    "3. ~~nulls~~\n",
    "2. skewness\n",
    "3. outliers\n",
    "3. important features and correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(990, 194)\n",
      "(594, 193)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('train.csv.zip', sep=',', header=0, compression='zip',encoding='cp1252')\n",
    "df_test =  pd.read_csv('test.csv.zip', sep=',', header=0, compression='zip',encoding='cp1252')\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>species</th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>134</td>\n",
       "      <td>Quercus_Afares</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018555</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>0.022461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>1076</td>\n",
       "      <td>Pterocarya_Stenoptera</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.029297</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008789</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>488</td>\n",
       "      <td>Betula_Austrosinensis</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.068359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064453</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058594</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.004883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>698</td>\n",
       "      <td>Acer_Rubrum</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>877</td>\n",
       "      <td>Alnus_Maximowiczii</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                species   margin1   margin2   margin3   margin4  \\\n",
       "77    134         Quercus_Afares  0.017578  0.015625  0.046875  0.013672   \n",
       "674  1076  Pterocarya_Stenoptera  0.001953  0.017578  0.003906  0.005859   \n",
       "295   488  Betula_Austrosinensis  0.001953  0.000000  0.005859  0.015625   \n",
       "426   698            Acer_Rubrum  0.000000  0.001953  0.015625  0.005859   \n",
       "550   877     Alnus_Maximowiczii  0.000000  0.000000  0.007812  0.011719   \n",
       "\n",
       "      margin5   margin6   margin7   margin8    ...      texture55  texture56  \\\n",
       "77   0.005859  0.007812  0.007812  0.000000    ...       0.000000   0.000000   \n",
       "674  0.029297  0.000000  0.021484  0.000000    ...       0.000000   0.000000   \n",
       "295  0.068359  0.000000  0.021484  0.000000    ...       0.064453   0.001953   \n",
       "426  0.033203  0.007812  0.005859  0.000000    ...       0.001953   0.000000   \n",
       "550  0.039062  0.000000  0.003906  0.001953    ...       0.000000   0.000977   \n",
       "\n",
       "     texture57  texture58  texture59  texture60  texture61  texture62  \\\n",
       "77    0.001953   0.016602   0.006836   0.006836        0.0   0.018555   \n",
       "674   0.000000   0.004883   0.039062   0.000000        0.0   0.008789   \n",
       "295   0.004883   0.007812   0.011719   0.000000        0.0   0.058594   \n",
       "426   0.002930   0.000000   0.000000   0.000000        0.0   0.039062   \n",
       "550   0.000977   0.011719   0.013672   0.035156        0.0   0.080078   \n",
       "\n",
       "     texture63  texture64  \n",
       "77    0.033203   0.022461  \n",
       "674   0.021484   0.000000  \n",
       "295   0.005859   0.004883  \n",
       "426   0.000000   0.001953  \n",
       "550   0.000000   0.018555  \n",
       "\n",
       "[5 rows x 194 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>margin9</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>799.595960</td>\n",
       "      <td>0.017412</td>\n",
       "      <td>0.028539</td>\n",
       "      <td>0.031988</td>\n",
       "      <td>0.023280</td>\n",
       "      <td>0.014264</td>\n",
       "      <td>0.038579</td>\n",
       "      <td>0.019202</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>0.007167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036501</td>\n",
       "      <td>0.005024</td>\n",
       "      <td>0.015944</td>\n",
       "      <td>0.011586</td>\n",
       "      <td>0.016108</td>\n",
       "      <td>0.014017</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.020291</td>\n",
       "      <td>0.008989</td>\n",
       "      <td>0.019420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>452.477568</td>\n",
       "      <td>0.019739</td>\n",
       "      <td>0.038855</td>\n",
       "      <td>0.025847</td>\n",
       "      <td>0.028411</td>\n",
       "      <td>0.018390</td>\n",
       "      <td>0.052030</td>\n",
       "      <td>0.017511</td>\n",
       "      <td>0.002743</td>\n",
       "      <td>0.008933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063403</td>\n",
       "      <td>0.019321</td>\n",
       "      <td>0.023214</td>\n",
       "      <td>0.025040</td>\n",
       "      <td>0.015335</td>\n",
       "      <td>0.060151</td>\n",
       "      <td>0.011415</td>\n",
       "      <td>0.039040</td>\n",
       "      <td>0.013791</td>\n",
       "      <td>0.022768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>415.250000</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>802.500000</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.011719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1195.500000</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.044922</td>\n",
       "      <td>0.029297</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.056153</td>\n",
       "      <td>0.029297</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022217</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.029297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1584.000000</td>\n",
       "      <td>0.087891</td>\n",
       "      <td>0.205080</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.169920</td>\n",
       "      <td>0.111330</td>\n",
       "      <td>0.310550</td>\n",
       "      <td>0.091797</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.076172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.429690</td>\n",
       "      <td>0.202150</td>\n",
       "      <td>0.172850</td>\n",
       "      <td>0.200200</td>\n",
       "      <td>0.106450</td>\n",
       "      <td>0.578130</td>\n",
       "      <td>0.151370</td>\n",
       "      <td>0.375980</td>\n",
       "      <td>0.086914</td>\n",
       "      <td>0.141600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id     margin1     margin2     margin3     margin4  \\\n",
       "count   990.000000  990.000000  990.000000  990.000000  990.000000   \n",
       "mean    799.595960    0.017412    0.028539    0.031988    0.023280   \n",
       "std     452.477568    0.019739    0.038855    0.025847    0.028411   \n",
       "min       1.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%     415.250000    0.001953    0.001953    0.013672    0.005859   \n",
       "50%     802.500000    0.009766    0.011719    0.025391    0.013672   \n",
       "75%    1195.500000    0.025391    0.041016    0.044922    0.029297   \n",
       "max    1584.000000    0.087891    0.205080    0.156250    0.169920   \n",
       "\n",
       "          margin5     margin6     margin7     margin8     margin9     ...      \\\n",
       "count  990.000000  990.000000  990.000000  990.000000  990.000000     ...       \n",
       "mean     0.014264    0.038579    0.019202    0.001083    0.007167     ...       \n",
       "std      0.018390    0.052030    0.017511    0.002743    0.008933     ...       \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000     ...       \n",
       "25%      0.001953    0.000000    0.005859    0.000000    0.001953     ...       \n",
       "50%      0.007812    0.015625    0.015625    0.000000    0.005859     ...       \n",
       "75%      0.017578    0.056153    0.029297    0.000000    0.007812     ...       \n",
       "max      0.111330    0.310550    0.091797    0.031250    0.076172     ...       \n",
       "\n",
       "        texture55   texture56   texture57   texture58   texture59   texture60  \\\n",
       "count  990.000000  990.000000  990.000000  990.000000  990.000000  990.000000   \n",
       "mean     0.036501    0.005024    0.015944    0.011586    0.016108    0.014017   \n",
       "std      0.063403    0.019321    0.023214    0.025040    0.015335    0.060151   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000977    0.000000    0.004883    0.000000   \n",
       "50%      0.004883    0.000000    0.005859    0.000977    0.012695    0.000000   \n",
       "75%      0.043701    0.000000    0.022217    0.009766    0.021484    0.000000   \n",
       "max      0.429690    0.202150    0.172850    0.200200    0.106450    0.578130   \n",
       "\n",
       "        texture61   texture62   texture63   texture64  \n",
       "count  990.000000  990.000000  990.000000  990.000000  \n",
       "mean     0.002688    0.020291    0.008989    0.019420  \n",
       "std      0.011415    0.039040    0.013791    0.022768  \n",
       "min      0.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000    0.000977  \n",
       "50%      0.000000    0.003906    0.002930    0.011719  \n",
       "75%      0.000000    0.023438    0.012695    0.029297  \n",
       "max      0.151370    0.375980    0.086914    0.141600  \n",
       "\n",
       "[8 rows x 193 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.041141939393939467, 0.009711506745082836)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = df_train.ix[:,2:].mean()\n",
    "( means.max() - means.min(), means.std() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          int64\n",
       "species    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes[df_train.dtypes!='float64']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((792, 192), (198, 192))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_train.ix[:,2:]\n",
    "Y = df_train.ix[:,1]\n",
    "\n",
    "enc = preprocessing.LabelEncoder()\n",
    "Y = enc.fit_transform(Y)\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X, Y, test_size=.2, random_state = 13)\n",
    "(X_tr.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score:  0.929292929293\n",
      "best params:  {'kernel': 'linear', 'tol': 0.001, 'C': 100}\n",
      "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Grid scores on development set:\n",
      "\n",
      "0.811 (+/-0.061) for {'kernel': 'linear', 'tol': 0.001, 'C': 10}\n",
      "0.811 (+/-0.061) for {'kernel': 'linear', 'tol': 0.0001, 'C': 10}\n",
      "0.924 (+/-0.062) for {'kernel': 'linear', 'tol': 0.001, 'C': 50}\n",
      "0.924 (+/-0.062) for {'kernel': 'linear', 'tol': 0.0001, 'C': 50}\n",
      "0.927 (+/-0.062) for {'kernel': 'linear', 'tol': 0.001, 'C': 75}\n",
      "0.927 (+/-0.062) for {'kernel': 'linear', 'tol': 0.0001, 'C': 75}\n",
      "0.929 (+/-0.060) for {'kernel': 'linear', 'tol': 0.001, 'C': 100}\n",
      "0.929 (+/-0.060) for {'kernel': 'linear', 'tol': 0.0001, 'C': 100}\n",
      "0.928 (+/-0.058) for {'kernel': 'linear', 'tol': 0.001, 'C': 125}\n",
      "0.928 (+/-0.058) for {'kernel': 'linear', 'tol': 0.0001, 'C': 125}\n",
      "0.928 (+/-0.058) for {'kernel': 'linear', 'tol': 0.001, 'C': 250}\n",
      "0.928 (+/-0.058) for {'kernel': 'linear', 'tol': 0.0001, 'C': 250}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9747474747474747"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = svm.SVC()\n",
    "\n",
    "param_grid = [\n",
    "  {'C': [10, 50, 75, 100, 125, 250], 'kernel': ['linear'], 'tol': [0.001, 0.0001]},\n",
    " ]\n",
    "\n",
    "gs = GridSearchCV(estimator=svc, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "gs = gs.fit(X_tr, y_tr)\n",
    "\n",
    "be = gs.best_estimator_\n",
    "print(\"best score: \" , gs.best_score_)\n",
    "print(\"best params: \" , gs.best_params_)\n",
    "print(be)\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = gs.cv_results_['mean_test_score']\n",
    "stds = gs.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, gs.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "svc = svm.SVC(C=be.C, kernel=be.kernel, probability=True).fit(X_tr, y_tr)\n",
    "svc.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc.fit(X, Y)\n",
    "\n",
    "data = svc.predict_proba(df_test.ix[:,1:])\n",
    "cols = enc.inverse_transform(svc.classes_)\n",
    "index = df_test['id'].values\n",
    "\n",
    "res = pd.DataFrame(data=data, columns=cols, index=index)\n",
    "\n",
    "res.to_csv('submission_svc.csv', index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1st attempt w/o unskewing: 2.49084\n",
    "# 2nd 2.33773"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "/opt/conda/lib/python3.5/site-packages/sklearn/metrics/scorer.py:136: DeprecationWarning: Scoring method log_loss was renamed to neg_log_loss in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'tol': 0.001, 'C': 1000}\n",
      "-0.898 (+/-0.039) for {'tol': 0.001, 'C': 100}\n",
      "[-0.91249094 -0.87144493 -0.85257967 -0.91449729 -0.96523712]\n",
      "-0.898 (+/-0.039) for {'tol': 0.0001, 'C': 100}\n",
      "[-0.91249094 -0.87144493 -0.85257967 -0.91449729 -0.96523712]\n",
      "-0.401 (+/-0.069) for {'tol': 0.001, 'C': 1000}\n",
      "[-0.37532259 -0.36803355 -0.33118005 -0.47373414 -0.51341367]\n",
      "-0.401 (+/-0.069) for {'tol': 0.0001, 'C': 1000}\n",
      "[-0.37532259 -0.36803355 -0.33118005 -0.47373414 -0.51341367]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/sklearn/model_selection/_search.py:680: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.97979797979797978"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'C':[100, 1000], 'tol': [0.001, 0.0001]}\n",
    "log_reg = linear_model.LogisticRegression(solver='lbfgs', multi_class='multinomial')\n",
    "clf = GridSearchCV(log_reg, params, scoring='log_loss', refit='True', n_jobs=-1, cv=5)\n",
    "clf.fit(X_tr, y_tr)\n",
    "\n",
    "print(\"best params: \" + str(clf.best_params_))\n",
    "for params, mean_score, scores in clf.grid_scores_:\n",
    "  print(\"%0.3f (+/-%0.03f) for %r\" % (mean_score, scores.std(), params))\n",
    "  print(scores)\n",
    "\n",
    "log_reg = linear_model.LogisticRegression(solver='lbfgs'\n",
    "                                          , multi_class='multinomial'\n",
    "                                          , C=clf.best_params_['C']\n",
    "                                         , tol=clf.best_params_['tol']).fit(X_tr, y_tr)\n",
    "log_reg.score(X_val, y_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_reg.fit(X, Y)\n",
    "\n",
    "data = log_reg.predict_proba(df_test.ix[:,1:])\n",
    "cols = enc.inverse_transform(log_reg.classes_)\n",
    "index = df_test['id'].values\n",
    "\n",
    "res = pd.DataFrame(data=data, columns=cols, index=index)\n",
    "\n",
    "res.to_csv('submission_lr.csv', index_label='id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
