{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "I'm trying to learn the very basics with this exercise. My goal is to train a linear regression model with a subset of columns from this interesting dataset in order to predict the value of a used car.\n",
    "\n",
    "Any help or advice is welcome!!!\n",
    "\n",
    "### Changelist\n",
    "\n",
    "* added name length feature\n",
    "\n",
    "* better study on the data\n",
    "* used seaborn to plot\n",
    "* added random forest and xgboost algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model, preprocessing, svm\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "import math\n",
    "import matplotlib\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data\n",
    "\n",
    "## Reading from file\n",
    "\n",
    "Just reading the file and printing some lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('autos.csv.gz', sep=',', header=0, compression='gzip',encoding='cp1252')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data from outliers and dirty values\n",
    "\n",
    "Cleaning data from duplicates, NaNs and selecting reasonable ranges for columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Too new: %d\" % df.loc[df.yearOfRegistration >= 2017].count()['name'])\n",
    "print(\"Too old: %d\" % df.loc[df.yearOfRegistration < 1950].count()['name'])\n",
    "print(\"Too cheap: %d\" % df.loc[df.price < 100].count()['name'])\n",
    "print(\"Too expensive: \" , df.loc[df.price > 150000].count()['name'])\n",
    "print(\"Too few km: \" , df.loc[df.kilometer < 5000].count()['name'])\n",
    "print(\"Too many km: \" , df.loc[df.kilometer > 200000].count()['name'])\n",
    "print(\"Too few PS: \" , df.loc[df.powerPS < 10].count()['name'])\n",
    "print(\"Too many PS: \" , df.loc[df.powerPS > 500].count()['name'])\n",
    "print(\"Fuel types: \" , df['fuelType'].unique())\n",
    "print(\"Offer types: \" , df['offerType'].unique())\n",
    "print(\"Sellers: \" , df['seller'].unique())\n",
    "print(\"Damages: \" , df['notRepairedDamage'].unique())\n",
    "print(\"Pics: \" , df['nrOfPictures'].unique()) # nrOfPictures : number of pictures in the ad (unfortunately this field contains everywhere a 0 and is thus useless (bug in crawler!) )\n",
    "print(\"Postale codes: \" , df['postalCode'].unique())\n",
    "print(\"Vehicle types: \" , df['vehicleType'].unique())\n",
    "print(\"Brands: \" , df['brand'].unique())\n",
    "\n",
    "#print(\"tourans: \" , df[df['model']=='touran'][['name','vehicleType','powerPS','yearOfRegistration']])\n",
    "\n",
    "# Cleaning data\n",
    "valid_models = df.dropna()\n",
    "\n",
    "#### Removing the duplicates\n",
    "dedups = valid_models.drop_duplicates(['name','seller','offerType','price','abtest','vehicleType','yearOfRegistration'\n",
    "                         ,'gearbox','powerPS','model','kilometer','monthOfRegistration','fuelType'\n",
    "                         ,'notRepairedDamage','postalCode'])\n",
    "\n",
    "#### Removing the outliers\n",
    "no_outliers = dedups[\n",
    "        (valid_models.yearOfRegistration <= 2016) \n",
    "      & (valid_models.yearOfRegistration >= 1950) \n",
    "      & (valid_models.price >= 100) \n",
    "      & (valid_models.price <= 150000) \n",
    "      & (valid_models.powerPS >= 10) \n",
    "      & (valid_models.powerPS <= 500)]\n",
    "\n",
    "print(\"\\nData kept for analisys: %d percent of the entire set\" % (100 * no_outliers['name'].count() / df['name'].count()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Studying correlations between some features and sell price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to see how data is distributed and how it's related to the sell price. I start considering the numeric fields already present in the dataset, then I'll do other studies after having encoded the string fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = no_outliers\n",
    "ax = sns.jointplot(x='powerPS', y='price',data=p[['powerPS','price']], alpha=0.1, size=8)\n",
    "plt.title('Price distribution for car power')\n",
    "\n",
    "plt.xlim(0, 501)\n",
    "plt.ylim(0, 160000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Price at varying yearOfRegistration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = no_outliers\n",
    "#plt.scatter(p['yearOfRegistration'], p['price'], alpha=.1, marker='o', color='b')\n",
    "ax = sns.jointplot(x='yearOfRegistration', \n",
    "                   y='price',\n",
    "                   data=p[['yearOfRegistration','price']], \n",
    "                   alpha=0.1, size=8)\n",
    "\n",
    "plt.title('Price distribution for year')\n",
    "\n",
    "plt.ylim(0, 160000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Price at varying kilometers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = no_outliers\n",
    "#plt.scatter(p['kilometer'], p['price'], alpha=.1, marker='o', color='b')\n",
    "ax = sns.jointplot(x='kilometer', y='price',data=p[['kilometer','price']], alpha=0.1, size=8)\n",
    "\n",
    "plt.title('Price distribution for kilometers')\n",
    "#plt.xlabel('Kilometers')\n",
    "#plt.ylabel('Price (logarithmic)')\n",
    "#plt.yscale('log')\n",
    "plt.ylim(0, 160000)\n",
    "plt.xticks([5000,10000,20000,30000,40000,50000,60000,70000,80000,90000,100000,125000,150000], rotation='vertical')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = no_outliers\n",
    "p['namelen'] = [len(n) for n in p['name']]\n",
    "\n",
    "print(p['namelen'].head())\n",
    "#plt.scatter(p['namelen'][p['model']=='golf'], p['price'][p['model']=='golf'], alpha=.1, marker='o', color='b')\n",
    "ax = sns.jointplot(x='namelen', y='price',data=p[['namelen','price']][p['model']=='golf'], alpha=0.1, size=8)\n",
    "\n",
    "p = p[p.namelen < 100] # removed the 22k chars name\n",
    "\n",
    "plt.title('Price distribution for name length')\n",
    "plt.ylim(0, 45000)\n",
    "plt.xlim(0, 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I plotted the name length vs car price for all the vw golfs and it seems that more complete names bring to a bit higher sell price. Another explanation could be that a longer name includes more optionals and accessories and therefore the price is obviously higher.\n",
    "\n",
    "Very short and very long names do not work well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting only relevant columns\n",
    "\n",
    "Here I select the columns that I think are useful for determining a car's price.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# only relevant columns\n",
    "rel_cols = no_outliers[['price'\n",
    "                        ,'yearOfRegistration'\n",
    "                        ,'gearbox'\n",
    "                        ,'powerPS'\n",
    "                        ,'model'\n",
    "                        ,'kilometer'\n",
    "                        ,'fuelType'\n",
    "                        ,'vehicleType'\n",
    "                        ,'monthOfRegistration'\n",
    "                        ,'brand'\n",
    "                        ,'notRepairedDamage'\n",
    "                       , 'namelen']]\n",
    "rel_cols.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding\n",
    "\n",
    "This part encodes the string fields to numerical values, in order to study the rest of the columns and to make some regressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = ['gearbox', 'notRepairedDamage', 'model', 'brand', 'fuelType', 'vehicleType']\n",
    "les = {}\n",
    "\n",
    "for l in labels:\n",
    "    les[l] = preprocessing.LabelEncoder()\n",
    "    les[l].fit(rel_cols[l])\n",
    "    #print(les[l].classes_)\n",
    "    tr = les[l].transform(rel_cols[l]) \n",
    "    rel_cols.loc[:, l + '_feat'] = pd.Series(tr, index=rel_cols.index)\n",
    "\n",
    "df_autos = rel_cols[ ['price'\n",
    "                        ,'yearOfRegistration'\n",
    "                        ,'powerPS'\n",
    "                        ,'kilometer'\n",
    "                        ,'monthOfRegistration'\n",
    "                        , 'namelen'] \n",
    "                    + [x+\"_feat\" for x in labels]]\n",
    "\n",
    "df_autos['yearOfRegistration'] = df_autos['yearOfRegistration'].apply(lambda x: x-2000)\n",
    "\n",
    "#print(df_autos['yearOfRegistration'])\n",
    "autos = df_autos.values.astype(float)\n",
    "\n",
    "Y = autos[:,0]\n",
    "X = autos[:,1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Studying the other correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.title('Pearson Correlation')\n",
    "sns.heatmap(df_autos.astype(float).corr(),\n",
    "            linewidths=0.1,\n",
    "            vmax=1.0, \n",
    "            square=True, \n",
    "            cmap=\"PuBuGn\", \n",
    "            linecolor='w', \n",
    "            annot=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = df_autos\n",
    "#plt.scatter(p['powerPS'], p['price'], alpha=.1, marker='o', color='b')\n",
    "ax = sns.jointplot(x='brand_feat', y='price',data=p[['brand_feat','price']], alpha=0.1, size=8)\n",
    "plt.title('Price distribution for brands')\n",
    "#plt.xlabel('Power in HP')\n",
    "#plt.ylabel('Price (logarithmic)')\n",
    "#plt.yscale('log')\n",
    "\n",
    "brands = zip(range(0, len(les['brand'].classes_)), les['brand'].classes_)\n",
    "\n",
    "s = ''\n",
    "for b in brands:\n",
    "    s = s + ' ' + str(b)\n",
    "\n",
    "print(\"brands: \" + s)\n",
    "\n",
    "plt.xlim(0, 41)\n",
    "plt.ylim(0, 160000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = df_autos[df_autos['brand_feat']==37]\n",
    "#plt.scatter(p['powerPS'], p['price'], alpha=.1, marker='o', color='b')\n",
    "ax = sns.jointplot(x='model_feat', y='price',data=p[['model_feat','price']], alpha=0.1, size=8)\n",
    "plt.title('Price distribution for VW models')\n",
    "#plt.xlabel('Power in HP')\n",
    "#plt.ylabel('Price (logarithmic)')\n",
    "#plt.yscale('log')\n",
    "\n",
    "model = zip(range(0, len(les['model'].classes_)), les['model'].classes_)\n",
    "\n",
    "s = ''\n",
    "for b in model:\n",
    "    s = s + ' ' + str(b)\n",
    "\n",
    "print(\"models: \" + s)\n",
    "\n",
    "#plt.xlim(0, 41)\n",
    "plt.ylim(0, 160000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = df_autos\n",
    "f = plt.figure()\n",
    "\n",
    "JG1 = sns.jointplot(x='fuelType_feat', y='price',data=p[['fuelType_feat','price']], alpha=0.1, size=4)\n",
    "JG2 = sns.jointplot(x='vehicleType_feat', y='price',data=p[['vehicleType_feat','price']], alpha=0.1, size=4)\n",
    "JG3 = sns.jointplot(x='gearbox_feat', y='price',data=p[['gearbox_feat','price']], alpha=0.1, size=4)\n",
    "JG4 = sns.jointplot(x='notRepairedDamage_feat', y='price',data=p[['notRepairedDamage_feat','price']], alpha=0.1, size=4)\n",
    "\n",
    "fuelTypes = zip(range(0, len(les['fuelType'].classes_)), les['fuelType'].classes_)\n",
    "s = ''\n",
    "for b in fuelTypes:\n",
    "    s = s + ' ' + str(b)\n",
    "print(\"Fuels: \" + s)\n",
    "\n",
    "vehicleTypes = zip(range(0, len(les['vehicleType'].classes_)), les['vehicleType'].classes_)\n",
    "s = ''\n",
    "for b in vehicleTypes:\n",
    "    s = s + ' ' + str(b)\n",
    "print(\"vehicleType: \" + s)\n",
    "\n",
    "gearboxes = zip(range(0, len(les['gearbox'].classes_)), les['gearbox'].classes_)\n",
    "s = ''\n",
    "for b in gearboxes:\n",
    "    s = s + ' ' + str(b)\n",
    "print(\"gearbox: \" + s)\n",
    "\n",
    "fuelTypes = zip(range(0, len(les['notRepairedDamage'].classes_)), les['notRepairedDamage'].classes_)\n",
    "s = ''\n",
    "for b in fuelTypes:\n",
    "    s = s + ' ' + str(b)\n",
    "print(\"notRepairedDamage: \" + s)\n",
    "\n",
    "#plt.xlim(0, 41)\n",
    "plt.ylim(0, 160000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correction\n",
    "\n",
    "Transforming the right-skewed sale price column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (12.0, 6.0)\n",
    "prices = pd.DataFrame({\"1. Before\":Y, \"2. After\":np.log1p(Y)})\n",
    "prices.hist()\n",
    "\n",
    "Y = np.log1p(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing with different models\n",
    "\n",
    "Trying with some model from scikit learn: LinearRegression, LR with L2 regularization and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, Lasso, LassoCV, LassoLarsCV\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "\n",
    "def cv_rmse(model, x, y):\n",
    "    r = np.sqrt(-cross_val_score(model, x, y, scoring=\"neg_mean_squared_error\", cv = 5))\n",
    "    return r\n",
    "\n",
    "r = range(2003, 2017)\n",
    "km_year = 10000\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linear = linear_model.LinearRegression()\n",
    "\n",
    "# Percent of the X array to use as training set. This implies that the rest will be test set\n",
    "test_size = .2\n",
    "\n",
    "#Split into train and validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state = 3)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "linear.fit(X_train, y_train)\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "score = linear.score(X_test, y_test)\n",
    "print('Variance score: %.2f' % score)\n",
    "\n",
    "print(\"rmse on validation set\", cv_rmse(linear, X_test, y_test).mean())\n",
    "\n",
    "# Last version results:\n",
    "# Variance score: 0.68\n",
    "# rmse on validation set 0.639555427197\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def calc_values(model, year, brand, car_model, vehicle, gearbox, fuel, powerPS, km, not_repaired_damage):\n",
    "    sample = [year\n",
    "          , powerPS\n",
    "          , km\n",
    "          , 1 # month\n",
    "          , 35 # namelen\n",
    "          , les['gearbox'].transform([gearbox])\n",
    "          , les['notRepairedDamage'].transform([not_repaired_damage])\n",
    "          , les['model'].transform([car_model])\n",
    "          , les['brand'].transform([brand])\n",
    "          , les['fuelType'].transform([fuel])\n",
    "          , les['vehicleType'].transform([vehicle])]\n",
    "    s_predict = np.expm1(model.predict([sample]))\n",
    "    return s_predict\n",
    "\n",
    "# [nan 'coupe' 'suv' 'kleinwagen' 'limousine' 'cabrio' 'bus' 'kombi' 'andere']\n",
    "vw1 = calc_values(linear, 2016, 'volkswagen', 'touran', 'bus', 'manuell', 'diesel', 105, 10000, 'nein')\n",
    "bmw  = calc_values(linear, 2016, 'bmw', '3er', 'limousine', 'manuell', 'diesel', 150, 10000, 'nein')\n",
    "fiat  = calc_values(linear, 2016, 'fiat', 'punto', 'kleinwagen', 'manuell', 'benzin', 60, 10000, 'nein')\n",
    "vw2 = calc_values(linear, 2016, 'volkswagen', 'tiguan', 'suv', 'manuell', 'diesel', 130, 10000, 'nein')\n",
    "\n",
    "print(vw1)\n",
    "print(bmw)\n",
    "print(fiat)\n",
    "print(vw2)\n",
    "\n",
    "values_linear  = [calc_values(linear, y, 'volkswagen', 'touran', 'bus', 'manuell', 'diesel', 120, km_year * (2017-y), 'nein') for y in r]\n",
    "values_linear2  = [calc_values(linear, y, 'volkswagen', 'touran', 'bus', 'manuell', 'diesel', 120, km_year * 2 * (2017-y), 'nein') for y in r]\n",
    "values_linear3  = [calc_values(linear, y, 'volkswagen', 'touran', 'bus', 'manuell', 'diesel', 120, km_year * 3 * (2017-y), 'nein') for y in r]\n",
    "plt.plot(r, values_linear, label='linear')\n",
    "plt.plot(r, values_linear2, label='linear 20000km_x_y')\n",
    "plt.plot(r, values_linear3, label='linear 30000km_x_y')\n",
    "\n",
    "#plt.grid()\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 regularized LR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "alphas = [0.005,0.05, 0.1, 0.3, 0.5, 0.7, 1, 2, 3, 5, 10, 20, 25, 30, 50]\n",
    "cv_lasso = [cv_rmse(Lasso(alpha = alpha), X_train, y_train).mean() for alpha in alphas]\n",
    "\n",
    "cv_lasso = pd.Series(cv_lasso, index = alphas)\n",
    "cv_lasso.plot(title = \"Validation\", figsize=(5,5))\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"rmse\")\n",
    "\n",
    "model_lasso = Lasso(alpha = cv_lasso.min()).fit(X_train, y_train)\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % model_lasso.score(X_test, y_test))\n",
    "\n",
    "coef = pd.Series(model_lasso.coef_, index = df_autos.iloc[:,1:].columns)\n",
    "\n",
    "imp_coef = pd.concat([coef.sort_values()])\n",
    "\n",
    "print(imp_coef)\n",
    "\n",
    "print(np.sqrt(np.mean((y_test - model_lasso.predict(X_test))**2)))\n",
    "print(\"rmse on validation set\", cv_rmse(model_lasso, X_test, y_test).mean())\n",
    "\n",
    "# Last version results:\n",
    "# 0.707839916347\n",
    "# rmse on validation set 0.708803418524\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vw1 = calc_values(model_lasso, 2016, 'volkswagen', 'touran', 'bus', 'manuell', 'diesel', 105, 10000, 'nein')\n",
    "bmw  = calc_values(model_lasso, 2016, 'bmw', '3er', 'limousine', 'manuell', 'diesel', 150, 10000, 'nein')\n",
    "fiat  = calc_values(model_lasso, 2016, 'fiat', 'punto', 'kleinwagen', 'manuell', 'benzin', 60, 10000, 'nein')\n",
    "vw2 = calc_values(model_lasso, 2016, 'volkswagen', 'tiguan', 'suv', 'manuell', 'diesel', 130, 10000, 'nein')\n",
    "\n",
    "print(vw1)\n",
    "print(bmw)\n",
    "print(fiat)\n",
    "print(vw2)\n",
    "\n",
    "values_lasso  = [calc_values(model_lasso, y, 'volkswagen', 'touran', 'bus', 'manuell', 'diesel', 120, km_year * (2017-y), 'nein') for y in r]\n",
    "values_lasso2  = [calc_values(model_lasso, y, 'volkswagen', 'touran', 'bus', 'manuell', 'diesel', 120, km_year * 2 * (2017-y), 'nein') for y in r]\n",
    "values_lasso3  = [calc_values(model_lasso, y, 'volkswagen', 'touran', 'bus', 'manuell', 'diesel', 120, km_year * 3 * (2017-y), 'nein') for y in r]\n",
    "plt.plot(r, values_lasso, label='lasso')\n",
    "plt.plot(r, values_lasso2, label='lasso 20000km_x_y')\n",
    "plt.plot(r, values_lasso3, label='lasso 30000km_x_y')\n",
    "\n",
    "#plt.grid()\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 regularized LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "alphas = [-10, -5, -2, -1, 0, 0.005,0.05, 0.1, 0.3, 1, 3, 5, 10, 20, 25, 30, 50]\n",
    "cv_ridge = [cv_rmse(Ridge(alpha = alpha), X_train, y_train).mean() for alpha in alphas]\n",
    "\n",
    "cv_ridge = pd.Series(cv_ridge, index = alphas)\n",
    "cv_ridge.plot(title = \"Validation\", figsize=(5,5))\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"rmse\")\n",
    "\n",
    "model_ridge = Ridge(alpha = cv_ridge.min()).fit(X_train, y_train)\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % model_ridge.score(X_test, y_test))\n",
    "\n",
    "coef = pd.Series(model_ridge.coef_, index = df_autos.iloc[:,1:].columns)\n",
    "\n",
    "imp_coef = pd.concat([coef.sort_values()])\n",
    "\n",
    "print(imp_coef)\n",
    "\n",
    "print(np.sqrt(np.mean((y_test - model_ridge.predict(X_test))**2)))\n",
    "print(\"rmse on validation set\", cv_rmse(model_ridge, X_test, y_test).mean())\n",
    "\n",
    "# Last version results:\n",
    "# 0.639334838313\n",
    "# rmse on validation set 0.639555431574\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vw1 = calc_values(model_ridge, 2016, 'volkswagen', 'touran', 'bus', 'manuell', 'diesel', 105, 10000, 'nein')\n",
    "bmw  = calc_values(model_ridge, 2016, 'bmw', '3er', 'limousine', 'manuell', 'diesel', 150, 10000, 'nein')\n",
    "fiat  = calc_values(model_ridge, 2016, 'fiat', 'punto', 'kleinwagen', 'manuell', 'benzin', 60, 10000, 'nein')\n",
    "vw2 = calc_values(model_ridge, 2016, 'volkswagen', 'tiguan', 'suv', 'manuell', 'diesel', 130, 10000, 'nein')\n",
    "\n",
    "print(vw1)\n",
    "print(bmw)\n",
    "print(fiat)\n",
    "print(vw2)\n",
    "\n",
    "values_ridge  = [calc_values(model_ridge, y, 'volkswagen', 'touran', 'bus', 'manuell', 'diesel', 120, km_year * (2017-y), 'nein') for y in r]\n",
    "values_ridge2  = [calc_values(model_ridge, y, 'volkswagen', 'touran', 'bus', 'manuell', 'diesel', 120, km_year * 2 * (2017-y), 'nein') for y in r]\n",
    "values_ridge3  = [calc_values(model_ridge, y, 'volkswagen', 'touran', 'bus', 'manuell', 'diesel', 120, km_year * 3 * (2017-y), 'nein') for y in r]\n",
    "plt.plot(r, values_ridge, label='ridge')\n",
    "plt.plot(r, values_ridge2, label='ridge 20000km_x_y')\n",
    "plt.plot(r, values_ridge3, label='ridge 30000km_x_y')\n",
    "\n",
    "#plt.grid()\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest = RandomForestRegressor(n_estimators = 50)\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % forest.score(X_test, y_test))\n",
    "\n",
    "print(np.sqrt(np.mean((y_test - forest.predict(X_test))**2)))\n",
    "print(\"rmse on validation set\", cv_rmse(forest, X_test, y_test).mean())\n",
    "\n",
    "# Last version results\n",
    "# Variance score: 0.88\n",
    "# 0.391895988852\n",
    "# rmse on validation set 0.426248010639\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vw1 = calc_values(forest, 2016, 'volkswagen', 'touran', 'bus', 'manuell', 'diesel', 105, 10000, 'nein')\n",
    "bmw  = calc_values(forest, 2016, 'bmw', '3er', 'limousine', 'manuell', 'diesel', 150, 10000, 'nein')\n",
    "fiat  = calc_values(forest, 2016, 'fiat', 'punto', 'kleinwagen', 'manuell', 'benzin', 60, 10000, 'nein')\n",
    "vw2 = calc_values(forest, 2016, 'volkswagen', 'tiguan', 'suv', 'manuell', 'diesel', 130, 10000, 'nein')\n",
    "\n",
    "print(vw1)\n",
    "print(bmw)\n",
    "print(fiat)\n",
    "print(vw2)\n",
    "\n",
    "#values_forest = [calc_values(forest     , y, 'volkswagen', 'touran', 'bus', 'manuell', 'diesel', 120, km_year * (2017-y), 'nein') for y in r]\n",
    "#values_forest2 = [calc_values(forest     , y, 'volkswagen', 'touran', 'bus', 'manuell', 'diesel', 120, km_year* 2 * (2017-y), 'nein') for y in r]\n",
    "#values_forest3 = [calc_values(forest     , y, 'volkswagen', 'touran', 'bus', 'manuell', 'diesel', 120, km_year* 3 * (2017-y), 'nein') for y in r]\n",
    "\n",
    "values_forest  = [calc_values(forest, y, 'audi', 'a3', 'coupe', 'manuell', 'diesel', 140, km_year * (2017-y), 'nein') for y in r]\n",
    "values_forest4 = [calc_values(forest, y, 'volkswagen', 'golf', 'coupe', 'manuell', 'diesel', 140, km_year * (2017-y), 'nein') for y in r]\n",
    "values_forest5 = [calc_values(forest, y, 'seat', 'ibiza', 'coupe', 'manuell', 'diesel', 140, km_year * (2017-y), 'nein') for y in r]\n",
    "values_forest6 = [calc_values(forest, y, 'dacia', 'logan', 'coupe', 'manuell', 'diesel', 140, km_year * (2017-y), 'nein') for y in r]\n",
    "\n",
    "\n",
    "plt.plot(r, values_forest, label='audi')\n",
    "plt.plot(r, values_forest4, label='vw')\n",
    "plt.plot(r, values_forest5, label='seat')\n",
    "plt.plot(r, values_forest6, label='dacia')\n",
    "\n",
    "#plt.grid()\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb.plot_importance(clf)\n",
    "\n",
    "#f0 = year\n",
    "#f1 = powerPS\n",
    "#f2 = km\n",
    "#f3 = month\n",
    "#f4 = namelen\n",
    "#f5 = gearbox\n",
    "#f6 = notRepairedDamage\n",
    "#f7 = model\n",
    "#f8 = brand\n",
    "#f9 = fuelType\n",
    "#f10 = vehicleType\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred = clf.predict(X_test)\n",
    "print(np.sqrt(np.mean((y_test - y_pred)**2)))\n",
    "\n",
    "# Last version results\n",
    "# 0.433305159267\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "values_clf  = [calc_values(clf, y, 'audi', 'a3', 'coupe', 'manuell', 'diesel', 140, km_year * (2017-y), 'nein') for y in r]\n",
    "values_clf2 = [calc_values(clf, y, 'audi', 'a3', 'coupe', 'manuell', 'diesel', 105, km_year * (2017-y), 'nein') for y in r]\n",
    "values_clf3 = [calc_values(clf, y, 'audi', 'a3', 'coupe', 'manuell', 'diesel', 200, km_year * (2017-y), 'nein') for y in r]\n",
    "values_clf  = [calc_values(clf, y, 'audi', 'a3', 'coupe', 'manuell', 'diesel', 140, km_year * (2017-y), 'nein') for y in r]\n",
    "values_clf4 = [calc_values(clf, y, 'volkswagen', 'golf', 'coupe', 'manuell', 'diesel', 140, km_year * (2017-y), 'nein') for y in r]\n",
    "values_clf5 = [calc_values(clf, y, 'seat', 'ibiza', 'coupe', 'manuell', 'diesel', 140, km_year * (2017-y), 'nein') for y in r]\n",
    "values_clf6 = [calc_values(clf, y, 'dacia', 'logan', 'coupe', 'manuell', 'diesel', 140, km_year * (2017-y), 'nein') for y in r]\n",
    "#plt.plot(r, values_clf2, label='audi 105cv')\n",
    "#plt.plot(r, values_clf3, label='audi 200cv')\n",
    "plt.plot(r, values_clf , label='audi 140cv')\n",
    "plt.plot(r, values_clf4, label='golf ')\n",
    "plt.plot(r, values_clf5, label='ibiza ')\n",
    "plt.plot(r, values_clf6, label='dacia ')\n",
    "\n",
    "#plt.grid()\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "I've tried to play with as much stuff as I could with this dataset in order to understand the very basic topics about:\n",
    "\n",
    "* data interpretation and selection\n",
    "* feature selection and labeling\n",
    "* data visualization\n",
    "* very rough ML algorithms application\n",
    "\n",
    "There's very much to improve both in how I managed all these steps and in the different outcomes of the predictions on the sell price. I'll experiment a bit more in the next few days, then I'll move on another dataset to learn more.\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
